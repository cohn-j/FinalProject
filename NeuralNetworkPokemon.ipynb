{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWwmfQS79qKT"
   },
   "source": [
    "You must catch them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHgcVpQW8mTo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "from PIL import Image, ImageOps\n",
    "from io import BytesIO\n",
    "from bunch import Bunch\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(\"FinalProject/input/pokemon_images/abra/2eb2a528f9a247358452b3c740df69a0.jpg\")\n",
    "img = image.load_img(image_path, target_size=image_size)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8duCvMe9rxx"
   },
   "source": [
    "Prepare a data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "KVcC3IU_8ulm",
    "outputId": "1e17f426-4754-470a-a1e9-98d52b2d41ef"
   },
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "num_classes = 150 # this many classes of Pokemon in the dataset\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=False,\n",
    "                                    brightness_range=(0.5,1.5),\n",
    "                                    rotation_range=10,\n",
    "                                    validation_split=0.2) # use the `subset` argument in `flow_from_directory` to access\n",
    "\n",
    "train_generator = data_generator.flow_from_directory('FinalProject/input/pokemon_images',\n",
    "                                                    target_size=(160,160), # chosen because this is size of the images in dataset\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    subset='training')\n",
    "\n",
    "val_generator = data_generator.flow_from_directory('FinalProject/input/pokemon_images',\n",
    "                                                    target_size=(160,160),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    subset='validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbSctk89uS8"
   },
   "source": [
    "Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2JyHXjB8uod"
   },
   "outputs": [],
   "source": [
    "# import the base model and pretrained weights\n",
    "\n",
    "custom_input = Input(shape=(160,160,3,))\n",
    "base_model = InceptionV3(include_top=False, \n",
    "                         weights='imagenet', \n",
    "                         input_tensor=custom_input, \n",
    "                         input_shape=None, \n",
    "                         pooling=None, \n",
    "                         classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0a4GjK18urH"
   },
   "outputs": [],
   "source": [
    "x = base_model.layers[-1].output # snag the last layer of the imported model\n",
    "\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x) # an optional extra layer\n",
    "x = Dense(num_classes,activation='softmax',name='predictions')(x) # our new, custom prediction layer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "# new model begins from the beginning of the imported model,\n",
    "# and the predictions come out of `x` (our new prediction layer)\n",
    "\n",
    "# let's train all the layers\n",
    "for layer in model.layers:\n",
    "    layer.training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fq-D-CX894XX"
   },
   "source": [
    "Optional: load pretrained model/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFN34YO_8utj"
   },
   "outputs": [],
   "source": [
    "# model = load_model('InceptionV3_Pokemon.h5/InceptionV3_Pokemon.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjFAxbFW8uxl"
   },
   "outputs": [],
   "source": [
    "# these are utilities to maximize learning, while preventing over-fitting\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=12, cooldown=6, rate=0.6, min_lr=1e-18, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=24, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROmZgRI486Fu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compile and train the network\n",
    "model.compile(optimizer=Adam(1e-8),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_generator, \n",
    "          validation_data=val_generator, \n",
    "          steps_per_epoch=17112//batch_size, \n",
    "          validation_steps=4202//batch_size, \n",
    "          epochs=200, # increase this if actually training\n",
    "          shuffle=True, \n",
    "          callbacks=[reduce_lr,early_stop] \n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJ-RIBci86It"
   },
   "outputs": [],
   "source": [
    "# here's how to save the model after training. Use ModelCheckpoint callback to save mid-training.\n",
    "# model.save('InceptionV3_Pokemon.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "ihaMnJcU86Lo",
    "outputId": "74b065d2-f498-4e85-d573-d908245ff8d0"
   },
   "outputs": [],
   "source": [
    "# preprocessing and predicting function for test images:\n",
    "def predict_this(this_img):\n",
    "    im = this_img.resize((160,160)) # size expected by network\n",
    "    img_array = np.array(im)\n",
    "    img_array = img_array/255 # rescale pixel intensity as expected by network\n",
    "    img_array = np.expand_dims(img_array, axis=0) # reshape from (160,160,3) to (1,160,160,3)\n",
    "    pred = model.predict(img_array)\n",
    "    return np.argmax(pred, axis=1).tolist()[0]\n",
    "\n",
    "classes = [_class for _class in os.listdir('FinalProject/input/pokemon_images')]\n",
    "classes.sort() # they were originally converted to number when loaded by folder, alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "n6VzZO2p86OJ",
    "outputId": "8c0b73cb-4737-4333-bb77-73851e786814"
   },
   "outputs": [],
   "source": [
    "url = 'https://i.imgur.com/5Nycvcx.jpg'\n",
    "response = requests.get(url)\n",
    "img_1 = Image.open(BytesIO(response.content))\n",
    "\n",
    "print(\"A wild {} appears!\".format(classes[predict_this(img_1)]))\n",
    "display(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sUSMQRO86Q0"
   },
   "outputs": [],
   "source": [
    "# the same thing, as a reusable function\n",
    "def identify(url):\n",
    "    response = requests.get(url)\n",
    "    _img = Image.open(BytesIO(response.content))\n",
    "    print(\"A wild {} appears!\".format(classes[predict_this(_img)]))\n",
    "    display(_img)\n",
    "\n",
    "identify(\"https://bit.ly/2VQ32fd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoUslkEY86So"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NeuralNetworkPokemon.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
